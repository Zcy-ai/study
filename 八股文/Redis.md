# Redis
## 数据类型

### 1. String类型
int、SDS是string类型的数据结构实现
SDS是简单动态字符串
* SDS 不仅可以保存文本数据，还可以保存二进制数据
* SDS获取字符串的时间复杂度是O（1）
* Redis的SDS API是安全的，拼接字符串不会造成缓冲区溢出

##### 应用场景
###### 缓存对象
* 直接缓存整个对象的JSON， SET user:1 '{"name": "zhacheny", "age": 22}'
* 采用将key进行分离为user:ID:属性，采用MSET存储，用MGET获取各属性值，命令例子：MSET user:1:name zhacheny user:1:age 22

###### 常规计数
因为Redis处理命令是单线程的，所以执行命令的过程是原子的。因此适用于计算访问次数、点赞、转发、库存数量
SET aritcle:readcount:1001 0
INCR aritcle:readcount:1001

###### 分布式锁
SET 命令有个 NX 参数可以实现「key不存在才插入」，可以用它来实现分布式锁
* 如果key不存在，则显示插入成功，可以用来表示加锁成功
* 如果key存在，则会显示插入失败，可以用来表示加锁失败
SET lock_key unique_value NX PX 10000 // 10000为过期时间10s
NX代表lock_key不存在时，才对lock_key进行设置操作

###### 共享session信息
通常我们在开发后台管理系统时，会使用 Session 来保存用户的会话(登录)状态，这些 Session 信息会被保存在服务器端，但这只适用于单系统应用，如果是分布式系统此模式将不再适用。例如用户一的 Session 信息被存储在服务器一，但第二次访问时用户一被分配到服务器二，这个时候服务器并没有用户一的 Session 信息，就会出现需要重复登录的问题，问题在于分布式系统每次会把请求随机分配到不同的服务器

### 2. String类型
按照插入顺序排序，可以从头部或尾部向List列表添加元素（以前双向链表或压缩列表，现在quicklist）

```Redis 
# 将一个或多个值value插入到key列表的表头(最左边)，最后的值在最前面
LPUSH key value [value ...] 
# 将一个或多个值value插入到key列表的表尾(最右边)
RPUSH key value [value ...]
# 移除并返回key列表的头元素
LPOP key     
# 移除并返回key列表的尾元素
RPOP key 
# 返回列表key中指定区间内的元素，区间以偏移量start和stop指定，从0开始
LRANGE key start stop
# 从key列表表头弹出一个元素，没有就阻塞timeout秒，如果timeout=0则一直阻塞
BLPOP key [key ...] timeout
# 从key列表表尾弹出一个元素，没有就阻塞timeout秒，如果timeout=0则一直阻塞
BRPOP key [key ...] timeout
```
##### 应用场景
* 消息保序
消息队列 三个需求：消息保序、处理重复的消息和保证消息的可靠性
LPUSH+RPOP或者RPUSH+LPOP实现消息队列
如何避免不停调用RPOP检查有没有新消息写入而占用CPU： BRPOP（阻塞式读取，有新数据写入队列再开始读区）
* 处理重复的消息
每个消息都有一个全局ID
当收到一条消息后，消费者程序就可以对比收到的消息 ID 和记录的已处理过的消息 ID，来判断当前收到的消息有没有经过处理。如果已经处理过，那么，消费者程序就不再进行处理了
List并不会为每个消息生成ID号，所以我们需要自行为每个消息生成一个全局唯一ID
* 保证消息的可靠性
当消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。
为了留存消息，List 类型提供了 BRPOPLPUSH 命令，这个命令的作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存。

### 3. Hash类型
底层数据结构： 压缩列表或哈希表
在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了
```Redis 
# 存储一个哈希表uid:1的键值
HMSET uid:1 name Tom age 15
# 存储一个哈希表uid:2的键值
HMSET uid:2 name Jerry age 13
# 获取哈希表用户id为1中所有的键值
HGETALL uid:1
```

### 4. Set类型
无序存储
底层数据结构：哈希表或整数集合
比较适合用来数据的去重和保障数据的唯一性，还可以用来统计多个集合的交集、错集和并集
不可重复点赞、共同好友、抽奖活动

### 5. Zset
相比于Set多了一个排序属性score，可以根据元素的权重来排序
底层数据结构：压缩列表或跳表
排行榜、电话姓名排序

### 6. BitMap
Bitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行0|1的设置，表示某个元素的值或者状态，时间复杂度为O(1)。
由于 bit 是计算机中最小的单位，使用它进行储存将非常节省空间，特别适合一些数据量大且使用二值统计的场景。

```Redis 
# 设置值，其中value只能是 0 和 1
SETBIT key offset value
# 获取值
GETBIT key offset
# 获取指定范围内值为 1 的个数
# start 和 end 以字节为单位
BITCOUNT key start end
```


### 7. HyperLogLog
直接使用Zset
```Redis 
# 存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。
GEOADD key longitude latitude member [longitude latitude member ...]
# 从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。
GEOPOS key member [member ...]
# 返回两个给定位置之间的距离。
GEODIST key member1 member2 [m|km|ft|mi]
# 根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。
GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]
```

### 8. Stream
消息队列的缺陷：不能持久化就无法可靠的保存消息，并且对于离线重连的客户端不能读取历史消息的缺陷
一个重复消费完就会被删除，而且生产者需要自行实现全局唯一ID
Stream 消息队列操作命令：
* XADD：插入消息，保证有序，可以自动生成全局唯一 ID；
* XLEN ：查询消息长度；
* XREAD：用于读取消息，可以按 ID 读取数据；
* XDEL ： 根据消息 ID 删除消息；
* DEL ：删除整个 Stream；
* XRANGE ：读取区间消息
* XREADGROUP：按消费组形式读取消息；
* XPENDING 和 XACK：
* XPENDING 命令可以用来查询每个消费组内所有消费者「已读取、但尚未确认」的消息；
* XACK 命令用于向消息队列确认消息处理已完成；

Redis使用了一个哈希表保存所有键值对，哈希表是一个数组，数组中的元素叫做哈希桶
结构：
redisDB：表示Redis数据库的结构，结构体里存放了指向dict结构的指针
dict：结构体里存放了两个哈希表，正常情况下使用哈希表1，哈希表2只在rehash的时候使用
dictctht：表示哈希表的结构，结构里存放了哈希表数组。数组中的每个元素都是指向一个哈希表节点的结构（dictEntry）的指针
dictEntry：表示哈希表节点的结构，结构里存放了key、value指针

#### 1.SDS
结构：len（字符串长度）、alloc（分配的空间长度）、flags（sds类型）、buf[]字节数组（用来保存实际数据）
获取字符串长度的时间复杂度O（1）
修改字符串时，alloc-len计算出剩余的空间大小，不满足空间要求的话需要扩展

#### 2。链表

#### 3. 压缩列表

#### 4. 哈希表
Redis采用链式哈希来解决哈希冲突，在不扩容哈希表的前提下，将具有相同哈希值的数据串起来
但随着链表的长度增加，查询这一节点的耗时会增加

rehash：
随着数据逐渐增多，触发了rehash操作
给哈希表2分配空间，一般会比哈希表1大2倍
给哈希表1的数据迁移到哈希表2中
迁移完成后，哈希表1的空间会被释放，并把哈希表2设置成哈希表1，然后在哈希表2新创建一个空白的哈希表

问题：
如果哈希表1的数据量非常大，那么在迁移至哈希表2的时候，因为会涉及大量的数据拷贝，会造成对redis的阻塞，无法服务其他请求

渐进式rehash：
给哈希表2分配空间
在rehash进行期间，每次哈希表元素进行增删改查时，redis除了会执行对应的操作以外，还会顺序将哈希表1中索引位置的所有key-value迁移到哈希表2上
随着哈希表操作请求的数量越多，最终在某个时间点会把哈希表1的所有key-value迁移到哈希表2，从而完成rehash操作

rehash触发
负载因子=哈希表已保存节点数量/哈希表大小 >1看情况执行 >5强制执行

#### 5. 整数集合
#### 6. 跳表
Zset底层使用了跳表，节点查找复杂度O（logN）
ZRANGEBYSCORE 范围查询
跳表其实是一种多层的有序链表
跳表节点结构：对象的元素值，元素权重值，后向指针，level数组（保存每层的前向指针和跨度）跨度：计算这个节点在跳表中的排位
跳表结构：头尾节点、最大层数、跳表长度

如果当前节点的权重小于要查找的权重，跳表就会访问该层的下一个节点
如果当前节点的权重等于要查找的权重时，并且当前节点的SDS类型数据小于要查找的数据时，跳表就会访问该层上的下一个节点

如何维持相邻两层的节点数量的比例为2:1？
跳表在创建节点的时候，随机生成每个节点的层数
跳表在创建节点的时候，会生成随机范围为0-1的一个随机数，如果这个随机数小于0.25，那么层数就增加一层，如何继续生成下一个随机数，直到随机数的结果大于0.25结束，最终确定该节点的层数

平衡树 vs 跳表
* 从内存占用上来比较，跳表比平衡树更灵活一些。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。
* 在做范围查找的时候，跳表比平衡树操作要简单。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。
* 从算法实现难度上来比较，跳表比平衡树要简单得多。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速

#### 7. quicklist
#### 8. listpack

## Redis持久化

### AOF
Redis先执行写操作命令，才将该命令记录到AOF日志里，避免额外的检查开销并且不会阻塞当前写操作命令的执行
风险：
第一个风险，执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。
第二个风险，前面说道，由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前写操作命令的执行，但是可能会给「下一个」命令带来阻塞风险。

Redis执行完写操作命令后，会将命令追加到server.aof_buf缓冲区；
然后通过write（）系统调用，将aof_buf缓冲区的数据写入到AOF文件，此时数据没有写入硬盘，而是拷贝到了内核缓冲区page_cache，等待内核将数据写入硬盘；
具体内核缓冲区的数据什么时候写入到硬盘，再由内核决定

Redis 提供了三种将 AOF 日志写回硬盘的策略，分别是 Always、Everysec 和 No，这三种策略在可靠性上是从高到低，而在性能上则是从低到高

随着执行的命令越多，AOF 文件的体积自然也会越来越大，为了避免日志文件过大， Redis 提供了 AOF 重写机制，它会直接扫描数据中所有的键值对数据，然后为每一个键值对生成一条写操作命令，接着将该命令写入到新的 AOF 文件，重写完成后，就替换掉现有的 AOF 日志。重写的过程是由后台子进程完成的，这样可以使得主进程可以继续正常处理命令。

### RDB
save、bgsave
全量快照，把内存中的所有数据都记录到磁盘中
执行bgsave时，redis依然可以继续处理操作命令
写时复制
执行bgsave命令时，会通过fork()创建子进程，此时子进程和父进程共享同一片内存数据，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个，于是就可以直接读取主线程（父进程）里的内存数据，并将数据写入到 RDB 文件。
如果主线程（父进程）要修改共享数据里的某一块数据（比如键值对 A）时，就会发生写时复制，于是这块数据的物理内存就会被复制一份（键值对 A'），然后主线程在这个数据副本（键值对 A'）进行修改操作。与此同时，bgsave 子进程可以继续把原来的数据（键值对 A）写入到 RDB 文件。

发生了写时复制后，RDB 快照保存的是原本的内存数据

### 混合使用AOF日志和内存快照



## 缓存雪崩、击穿、穿透
应用        redis       mysql

---缓存中读取数据--->
<--缓存不存在-------
------从数据库读取数据------->
<-----返回数据库中的数据------
--将数据加载到缓存-->

#### 缓存雪崩
缓存雪崩：当大量缓存在同一时间失效或者Redis故障时，如果此时有大量的用户请求，都无法在redis中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，造成整个系统崩溃
本质是大量缓存都未命中或者redis中途故障

应对大量数据同时过期：
1. 均匀设置过期时间：给这些数据的过期时间加上一个随机数
2. 互斥锁：如果发现访问的数据不在redis里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存（设置超时时间）
3. 双key策略：对缓存数据使用两个key，主key，会设置过期时间，备key，不会设置过期，它们只是key不一样，但是value的值是一样的，相当于给缓存数据做了个副本。当业务线程访问不到主key的缓存数据时，就直接返回备key的缓存数据
4. 后台更新缓存：业务线程不再负责更新缓存，缓存也不设置有效期，而是让缓存“永久有效”，并将缓存更新的工作交由后台线程定时更新。在业务线程发现缓存数据失效后（缓存数据被淘汰），通过消息队列发送一条消息通知后台线程更新缓存，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；不存在就读取数据库数据，并将数据加载到缓存。这种方式相比第一种方式缓存的更新会更及时，用户体验也比较好。
缓存预热：在业务刚上线时，我们最好提前把数据缓起来，而不是等待用户访问才来触发缓存构建

应对Redis服务宕机：
1. 服务熔断或请求限流机制：因为redis故障宕机而导致缓存雪崩问题，我们可以启用服务熔断机制，暂停业务应用对缓存服务的访问，直接返回错误。为了减少对业务的影响，启用限流机制，将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务
2. 构建Redis缓存高可靠集群：我们通过主从节点的方式构建Redis缓存高可靠集群

#### 缓存击穿
缓存击穿：缓存中的某个热点数据过期了，此时大量的请求访问该热点数据，就无法从缓存中获取，直接访问数据库，数据库很容易被高并发的请求冲垮（本质还是缓存雪崩）
互斥锁方案、不给热点数据设置过期时间，由后台异步更新缓存

#### 缓存穿透
当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题

发生情况：业务误操作、黑客恶意攻击

1. 非法请求限制：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在API入口处我们要判断请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出恶意就直接返回错误
2. 缓存空值或默认值：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或默认值，这样后续请求就会直接从缓存中读取空值或默认值，而不会继续查询数据库
3. 使用布隆过滤器做快速判断数据是否存在，避免通过数据库判断数据是否存在

使用N个哈希函数分别对数据做哈希计算，得到N个哈希值；
将第一步的N个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置；
将每个哈希值在位图数组对应位置的值设置为1；
当应用要查询x是否在数据库中时，通过布隆过滤器查询对应位置是否全为1；
由于存在哈希冲突的可能性，所以查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到不存在，数据库中就一定不存在这个数据；